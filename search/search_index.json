{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SiteVisor","text":"<p>Digital Twin Application for Building Monitoring and Asset Management</p> <p>SiteVisor is a Digital Twin Application for building monitoring and asset management, particularly for offices and industrial sites. The web applicatioon will simulate real world objects through a 3D digital twin, enabling users to see the site conditions, manage assets, and streamline maintenance tasks effectively. Check the User Guide to get started.</p>"},{"location":"architecture/architecture-frontend/","title":"Frontend overview","text":"<p>The application is built with SvelteKit framework with the main component using three.js library to create and render 3D graphics in a web browser using WebGL.</p> <p>The image below shows the inheritance diagram for the main objects in the 3D scene/viewer, representing SiteVisor's model.</p> <p></p> <p>Object3D and Mesh are three.js classes and provide a base for the SiteVisor objects.</p> <p>SiteVisor introduces custom objects extending three.js classes. These are: <code>Volume</code>, <code>Point3D</code> and <code>Plane</code>, which all inherit from three.js Mesh class. These three objects should provide a solid basis to visualise SiteVisor's model to the user. All other objects in the scene will inherit from them.</p> <p>Below is a short description of SiteVisor's objects in the 3D scene:</p> <ul> <li><code>Level</code> - represents a condignation of a building encompassing rooms.</li> <li><code>Room</code> - an individual room in a building.</li> <li><code>Sensor</code> - representation of a physical sensor on site.</li> <li><code>PointOfInterest</code> - any point of interest marked by the user. Can be an item for maintenance etc.</li> <li><code>ReferencePlane</code> - a base plane in the 3D model represented by a helper grid, used as a reference to place objects in the 3D space.</li> <li><code>Heatmap</code> - textured plane showing a heatmap produced by interpolating data from multiple sensors. For example, temperature across the building.</li> </ul>"},{"location":"architecture/architecture-overview/","title":"Architecture Overview","text":"<p>The diagram below shows the general project architecture, from data perspective, in its minimal form. There could be further extensions added including more data stream types available as inputs. For example MQTT Clients through MQTT bridge or HTTP Clients through Kafka Bridge.</p> <p>Apache Kafka is at the core of the project. This Kafka cluster is deployed and managed by Strimzi operator.</p> <p></p>"},{"location":"architecture/architecture-overview/#realtime-data-stream","title":"Realtime data stream","text":"<p>The application is meant to provide users with a Digital Twin backed by realtime data. For this reason Kafka was chosen as the main technology for communication. </p> <p>To achieve the realtime delivery to the browser, Kafka Websocket Proxy is used as a bridge between Kafka Cluster and a Websocket Client in the frontend of SiteVisor application.</p>"},{"location":"architecture/architecture-overview/#data-persistence","title":"Data persistence","text":"<p>The sensor data needs to be stored in a database, from where it can be accessed by the SiteVisor backend service. This wil be used to produce various analytics presented to the users in a form of charts or heatmaps etc.</p>"},{"location":"dev-guide/docker-deployment/","title":"Running the App with Docker","text":""},{"location":"dev-guide/docker-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: Ensure Docker is installed on your system. You can download and install Docker from Docker's official website.</li> <li>Docker Compose: Docker Compose is included in Docker Desktop for Windows and macOS. For Linux, you may need to install it separately.</li> </ul>"},{"location":"dev-guide/docker-deployment/#running-the-application","title":"Running the application","text":"<p>Building the Docker Image:</p> <p>Navigate to the root directory of the sitevisor project and then build the Docker image:</p> <pre><code>docker-compose build\n</code></pre> <p>Starting the Application:</p> <p>After the build completes, you can start the application using Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre> <p>Accessing the Application</p> <p>Once the container is running, access the app by navigating to http://localhost:8080 in a web browser.</p> <p>Stopping the Application</p> <p>To stop the application, you can use the following command:</p> <pre><code>docker-compose down\n</code></pre>"},{"location":"dev-guide/ingress-config/","title":"Overall Ingress configuration","text":"<p>The deployment steps outlined in the guide for each component contain separate Ingress resources specified for each specific component, like the frontend, backend or Kafka Bridge.</p> <p>To simplify management of the ingress resources, we can also create a combined Ingress resource to handle all services per namespace.</p> <p>Ingress for SiteVisor frontend and backend services:</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sitevisor-ingress\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - pathType: Prefix\n        path: /\n        backend:\n          service:\n            name: sitevisor-frontend-service\n            port:\n              number: 3000\n      - pathType: Prefix\n        path: /api\n        backend:\n          service:\n            name: sitevisor-backend-service\n            port:\n              number: 8000\n      - pathType: Prefix\n        path: /static/rest_framework\n        backend:\n          service:\n            name: sitevisor-backend-service\n            port:\n              number: 8000\n\" | kubectl apply -f -\n</code></pre> <p>Ingress for Kafka related services:</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: kafka-ingress\n  namespace: kafka\n  annotations:\n    nginx.ingress.kubernetes.io/proxy-read-timeout: '3600'\n    nginx.ingress.kubernetes.io/proxy-send-timeout: '3600'\n    nginx.ingress.kubernetes.io/server-snippets: |\n      location /socket {\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_http_version 1.1;\n        proxy_set_header X-Forwarded-Host $http_host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host $host;\n        proxy_set_header Connection 'upgrade';\n        proxy_cache_bypass $http_upgrade;\n      }\nspec:\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - path: /topics\n        pathType: Prefix\n        backend:\n          service:\n            name: kafka-bridge-bridge-service\n            port:\n              number: 8088\n      - path: /socket\n        pathType: Prefix\n        backend:\n          service:\n            name: kafka-websocket-proxy-service\n            port:\n              number: 8078\n  ingressClassName: nginx\n\" | kubectl apply -f -\n</code></pre>"},{"location":"dev-guide/kind-deployment/","title":"Running the app in Kind","text":""},{"location":"dev-guide/kind-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: Ensure Docker is installed on your system. You can download and install Docker from Docker's official website.</li> <li>Kind: Install kind on your machine. Follow the installation instructions on the kind website.</li> <li>Added <code>127.0.0.1 sitevisor.local</code> \u00ecn <code>/etc/hosts</code></li> </ul>"},{"location":"dev-guide/kind-deployment/#kind-deployment","title":"Kind deployment","text":"<p>Create the Kind cluster:</p> <pre><code>kind create cluster\n</code></pre> <p>Build and Load the Docker Image into kind:</p> <pre><code>docker build -t sitevisor:dev .\n</code></pre> <p>Load the Image into your kind Cluster:</p> <pre><code>kind load docker-image sitevisor:dev\n</code></pre> <p>Create the deployment:</p> <pre><code>echo \"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sitevisor-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sitevisor\n  template:\n    metadata:\n      labels:\n        app: sitevisor\n    spec:\n      containers:\n      - name: sitevisor\n        image: sitevisor:dev\n        ports:\n        - containerPort: 3000\n\" | kubectl apply -f -\n</code></pre> <p>Create a service to expose the application:</p> <pre><code>echo \"\napiVersion: v1\nkind: Service\nmetadata:\n  name: sitevisor-frontend-service\nspec:\n  type: ClusterIP\n  selector:\n    app: sitevisor\n  ports:\n    - protocol: TCP\n      port: 3000\n      targetPort: 3000\n\" | kubectl apply -f -\n</code></pre> <p>Ingress for SiteVisor frontend: Alternatively you can use a combined Ingress resource for both frontend and backend services.</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sitevisor-frontend-ingress\nspec:\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - pathType: Prefix\n        path: /\n        backend:\n          service:\n            name: sitevisor-frontend-service\n            port:\n              number: 3000\n  ingressClassName: nginx\n\" | kubectl apply -f -\n</code></pre> <p>Access the application:</p> <p>Open your browser and go to http://sitevisor.local:8080.</p> <p>Cleanup</p> <pre><code>kind delete cluster\n</code></pre>"},{"location":"dev-guide/local-deployment/","title":"Developer Guide","text":"<p>This section describes how to set up and run the application in a local development environment. This is ideal for development and testing purposes.</p>"},{"location":"dev-guide/local-deployment/#prerequisites","title":"Prerequisites","text":"<p>Ensure Node.js is installed on your system.</p>"},{"location":"dev-guide/local-deployment/#local-deployment","title":"Local deployment","text":"<p>Install dependencies with:</p> <pre><code>npm install\n</code></pre> <p>Set <code>VITE_BASE_URL</code> and <code>VITE_WEBSOCKET_URL</code> in .env file.</p> <p>Start a development server:</p> <pre><code>npm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n</code></pre>"},{"location":"dev-guide/local-deployment/#building","title":"Building","text":"<p>To create a production version of your app:</p> <pre><code>npm run build\n</code></pre>"},{"location":"user-guide/","title":"User Guide","text":"<p>The user experience in the application is focused around the 3D viewer rendering a model of your facility. Use the tool sidebar to select different interaction options, such as creating a new room or adding a sensor.</p>"},{"location":"user-guide/project-management/","title":"Project Management","text":"<p>This guide describes Project management in SiteVisor.</p>"},{"location":"user-guide/project-management/#create-a-new-project","title":"Create a new Project","text":"<p>Directly after loggin in, you are presented with a list of your projects. Use the last card on the list to enter the name of your new project and approve with <code>Create</code> button.</p> <p></p> <p>After that you should see a new card added with the name of your project.</p>"},{"location":"user-guide/project-management/#configure-project","title":"Configure Project","text":"<p>At any time you can change the configuration of your projects by using the <code>Manage</code> button.</p> <p></p> <p>This brings us to the Project management page.</p>"},{"location":"user-guide/project-management/#kafka-topics","title":"Kafka Topics","text":"<p>The most important configuration are <code>Kafka Topics</code>. This field is used to input names of Kafka topics to which we would like to establish connection in our Project.</p> <p>We can list as many topics as we wish. Each topic name should be separated by a comma, for example:</p> <pre><code>my-topic,datastream42,env-data\n</code></pre> <p>would establish connections to three topics: - my-topic - datastream42 - env-data</p> <p></p>"},{"location":"user-guide/project-management/#sensor-types","title":"Sensor Types","text":"<p>Notice the <code>Sensor Types</code> section. Two types of sensors are added to each project by default: <code>Temperature</code> and <code>Humidity</code>. You can add a new type or delete any type as you wish. The types are used to filter the sensors in Sensor listing pages and the sensor data Heatmap.</p>"},{"location":"sitevisor-backend/docs/deployment/kafka-deployment/","title":"Creating an Apache Kafka cluster","text":""},{"location":"sitevisor-backend/docs/deployment/kafka-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running Kind cluster</li> <li>Added <code>127.0.0.1 sitevisor.local</code> \u00ecn <code>/etc/hosts</code></li> </ul> <p>Create a <code>kafka</code> namespace:</p> <pre><code>kubectl create namespace kafka\n</code></pre> <p>Apply the Strimzi install files:</p> <pre><code>kubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></pre> <p>Create a new Kafka custom resource:</p> <p>This sets up a small persistent Apache Kafka Cluster with one node for Apache Zookeeper and Apache Kafka:</p> <pre><code>echo \"\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: kafka-sitevisor-cluster\nspec:\n  kafka:\n    version: 3.6.1\n    replicas: 1\n    listeners:\n      - name: plain\n        port: 9092\n        type: internal\n        tls: false\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n    config:\n      offsets.topic.replication.factor: 1\n      transaction.state.log.replication.factor: 1\n      transaction.state.log.min.isr: 1\n      default.replication.factor: 1\n      min.insync.replicas: 1\n      inter.broker.protocol.version: '3.6'\n    storage:\n      type: jbod\n      volumes:\n      - id: 0\n        type: persistent-claim\n        size: 25Gi\n        deleteClaim: false\n  zookeeper:\n    replicas: 1\n    storage:\n      type: persistent-claim\n      size: 25Gi\n      deleteClaim: false\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\n\" | kubectl apply -n kafka -f -\n</code></pre> <p>Create the KafkaBridge resource:</p> <pre><code>echo \"\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaBridge\nmetadata:\n  name: kafka-bridge\n  namespace: kafka\nspec:\n  replicas: 1\n  bootstrapServers: kafka-sitevisor-cluster-kafka-bootstrap:9092\n  http:\n    port: 8088\n    cors:\n      allowedMethods:\n        - GET\n        - POST\n        - DELETE\n        - ACCEPT\n        - OPTIONS\n      allowedOrigins:\n        - 'http://localhost:5173'\n  consumer:\n    config:\n      auto.offset.reset: earliest\n  producer:\n    config:\n      delivery.timeout.ms: 300000\n\" | kubectl apply -f -\n</code></pre> <p>Expose KafkaBridge Service:</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: kafka-bridge\n  namespace: kafka\nspec:\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - path: /topics\n        pathType: Prefix\n        backend:\n          service:\n            name: kafka-bridge-bridge-service\n            port:\n              number: 8088\n  ingressClassName: nginx\n\" | kubectl apply -f -\n</code></pre> <p>Create a test Kafka Topic:</p> <pre><code>echo \"\napiVersion: kafka.strimzi.io/v1beta1\nkind: KafkaTopic\nmetadata:\n  name: my-topic\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: 'kafka-sitevisor-cluster'\nspec:\n  partitions: 3\n  replicas: 1\n\" | kubectl create -f -\n</code></pre> <p>Curl a test message to Kafka:</p> <pre><code>curl -X POST http://sitevisor.local:8080/topics/my-topic \\\n     -H \"Content-Type: application/vnd.kafka.json.v2+json\" \\\n     --data '{\"records\": [{\"value\": \"Test message...\"}]}'\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/kafka-websocket-proxy-deployment/","title":"Kafka Websocket Proxy","text":"<p>This guide describes setting up Kafka Websocket Proxy. This proxy serves as a bridge between a Kafka cluster and WebSocket clients, enabling real-time data streaming from Kafka topics to WebSocket clients.</p>"},{"location":"sitevisor-backend/docs/deployment/kafka-websocket-proxy-deployment/#prerequisites","title":"Prerequisites:","text":"<ul> <li>Kafka Cluster deployed</li> <li>Added <code>127.0.0.1 sitevisor.local</code> \u00ecn <code>/etc/hosts</code></li> </ul> <p>Deploy the Kafka WebSocket Proxy:</p> <pre><code>echo \"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kafka-websocket-proxy\n  namespace: kafka\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kafka-websocket-proxy\n  template:\n    metadata:\n      labels:\n        app: kafka-websocket-proxy\n    spec:\n      containers:\n      - name: kafka-websocket-proxy\n        image: kpmeen/kafka-websocket-proxy:1.2.0\n        ports:\n        - containerPort: 8078\n        env:\n          - name: WSPROXY_KAFKA_BOOTSTRAP_HOSTS\n            value: 'kafka-sitevisor-cluster-kafka-bootstrap:9092'\n\" | kubectl apply -f - \n</code></pre> <p>Create a Serivce for the Kafka WebSocket Proxy:</p> <pre><code>echo \"\napiVersion: v1\nkind: Service\nmetadata:\n  name: kafka-websocket-proxy-service\n  namespace: kafka\nspec:\n  type: ClusterIP\n  selector:\n    app: kafka-websocket-proxy\n  ports:\n    - port: 8078\n      targetPort: 8078\n      protocol: TCP\n\" | kubectl apply -f -\n</code></pre> <p>Ingress for the Kafka WebSocket Proxy:</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n name: kafka-websocket\n namespace: kafka\n annotations:\n  nginx.ingress.kubernetes.io/proxy-read-timeout: '3600'\n  nginx.ingress.kubernetes.io/proxy-send-timeout: '3600'\n  nginx.ingress.kubernetes.io/server-snippets: |\n   location / {\n    proxysetheader Upgrade $httpupgrade;\n    proxyhttpversion 1.1;\n    proxysetheader X-Forwarded-Host $httphost;\n    proxysetheader X-Forwarded-Proto $scheme;\n    proxysetheader X-Forwarded-For $remoteaddr;\n    proxysetheader Host $host;\n    proxysetheader Connection 'upgrade';\n    proxycachebypass $httpupgrade;\n    }\nspec:\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - path: /socket\n        pathType: Prefix\n        backend:\n          service:\n            name: kafka-websocket-proxy-service\n            port:\n              number: 8078\n  ingressClassName: nginx\n\" | kubectl apply -f -\n</code></pre> <p>Test connection again and see if the data is received through the websocket:</p> <pre><code>curl -X POST http://sitevisor.local:8080/topics/my-topic \\\n     -H \"Content-Type: application/vnd.kafka.json.v2+json\" \\\n     --data '{\"records\": [{\"value\": \"Test message...\"}]}'\n</code></pre> <p>Running a Kafka Producer for connection testing: Run a simple producer to send messages to a Kafka topic:</p> <pre><code>kubectl -n kafka run kafka-producer -ti --image=quay.io/strimzi/kafka:0.39.0-kafka-3.6.1 --rm=true --restart=Never -- bin/kafka-console-producer.sh --bootstrap-server kafka-sitevisor-cluster-kafka-bootstrap:9092 --topic my-topic\n</code></pre> <p>WebSocket URL for connecting clients:</p> <p>This WebSocket URL is used by clients to connect to the Kafka WebSocket Proxy. Clients can subscribe to the Kafka topic <code>my-topic</code> through this WebSocket connection to receive real-time messages.</p> <pre><code>ws://localhost:8078/socket/out?clientId=console_consumer&amp;topic=my-topic\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/kind-cluster/","title":"Creating Kind Cluster","text":"<p>kind is a tool for running local Kubernetes clusters using Docker.</p>"},{"location":"sitevisor-backend/docs/deployment/kind-cluster/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: Ensure Docker is installed on your system. You can download and install Docker from Docker's official website.</li> <li>Kind: Install kind on your machine. Follow the installation instructions on the kind website.</li> </ul> <p>Create the Kind cluster:</p> <pre><code>echo \"\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnetworking:\n  ipFamily: dual\nnodes:\n- role: control-plane\n  image: kindest/node:v1.29.2\n  kubeadmConfigPatches:\n  - |\n    kind: InitConfiguration\n    nodeRegistration:\n      kubeletExtraArgs:\n        node-labels: 'ingress-ready=true'\n  extraPortMappings:\n  - containerPort: 80\n    hostPort: 8080\n    listenAddress: 0.0.0.0\n    protocol: TCP\n  - containerPort: 443\n    hostPort: 8443\n    listenAddress: 0.0.0.0\n    protocol: TCP\n\" | kind create cluster --config=-\n</code></pre> <p>NGINX Ingress Controller:</p> <p>The manifests below contain kind specific patches to forward the hostPorts to the ingress controller:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/kind-deployment/","title":"Deploying the SiteVisor Backend","text":""},{"location":"sitevisor-backend/docs/deployment/kind-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running Kind cluster</li> <li>PostgreSQL database deployed</li> <li>Added <code>127.0.0.1 sitevisor.local</code> \u00ecn <code>/etc/hosts</code></li> </ul> <p>Build and Load the Docker Image into kind:</p> <pre><code>docker build -t sitevisor-backend:dev .\n</code></pre> <p>Load the Image into your kind Cluster:</p> <pre><code>kind load docker-image sitevisor-backend:dev\n</code></pre> <p>Create the deployment:</p> <pre><code>echo \"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sitevisor-backend-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sitevisor-backend\n  template:\n    metadata:\n      labels:\n        app: sitevisor-backend\n    spec:\n      initContainers:\n      - name: apply-migrations\n        image: sitevisor-backend:dev\n        command: ['python', 'manage.py', 'migrate']\n      containers:\n      - name: sitevisor-backend\n        image: sitevisor-backend:dev\n        ports:\n        - containerPort: 8000\n\" | kubectl apply -f -\n</code></pre> <p>Create a service to expose the application:</p> <pre><code>echo \"\napiVersion: v1\nkind: Service\nmetadata:\n  name: sitevisor-backend-service\nspec:\n  selector:\n    app: sitevisor-backend\n  ports:\n  - protocol: TCP\n    port: 8000\n    targetPort: 8000\n\" | kubectl apply -f -\n</code></pre> <p>Ingress for SiteVisor backend:</p> <pre><code>echo \"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: sitevisor-backend-ingress\nspec:\n  rules:\n  - host: sitevisor.local\n    http:\n      paths:\n      - pathType: Prefix\n        path: /api\n        backend:\n          service:\n            name: sitevisor-backend-service\n            port:\n              number: 8000\n      - pathType: Prefix\n        path: /static/rest_framework\n        backend:\n          service:\n            name: sitevisor-backend-service\n            port:\n              number: 8000\n  ingressClassName: nginx\n\" | kubectl apply -f -\n</code></pre> <p>Access the application's backend API:</p> <p>Open your browser and go to http://sitevisor.local:8080/api/</p>"},{"location":"sitevisor-backend/docs/deployment/kind-deployment/#tips","title":"Tips","text":"<p>For testing the Django backend, you can expose postgreSQL with:</p> <pre><code>kubectl port-forward svc/sitevisor-db-cluster-rw 5432:5432 -n postgres-operator\n</code></pre> <p>and then use <code>POSTGRES_HOST=localhost</code> in the <code>.env</code> file of Django backend. This removes the need to rebuild and load Docker container into Kind cluster while developing.</p> <p>Then run the Django app with:</p> <pre><code>python manage.py runserver\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/kind-deployment/#tests","title":"Tests","text":"<p>To run tests set the env variable <code>DJANGO_ENV='dev'</code>. This uses local SQLite database. Then run:</p> <pre><code>python manage.py test -v 2\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/postgres-deployment/","title":"PostgreSQL deployment","text":"<p>This section provides steps required to deploy the CloudNativePG operator which manages PostgreSQL workloads on Kubernetes cluster.</p>"},{"location":"sitevisor-backend/docs/deployment/postgres-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running Kind cluster</li> </ul> <p>Create a Namespace for the PostgreSQL Operator:</p> <pre><code>kubectl create namespace postgres-operator\n</code></pre> <p>Deploy the CNP Operator:</p> <pre><code>kubectl apply -n cnpg-system -f https://github.com/cloudnative-pg/cloudnative-pg/releases/download/v1.22.1/cnpg-1.22.1.yaml\n</code></pre> <p>Create a Secret for the PostgreSQL Superuser:</p> <pre><code>kubectl create secret generic postgres-superuser-secret --from-literal=username=postgresadmin --from-literal=password=supersecret --namespace postgres-operator\n</code></pre> <p>Create a Secret for the Application Database User:</p> <pre><code>kubectl create secret generic sitevisor-user-secret  --from-literal=username=sitevisoruser --from-literal=password=secret --namespace postgres-operator\n</code></pre> <p>Deploy a PostgreSQL Cluster:</p> <pre><code>echo \"\napiVersion: postgresql.cnpg.io/v1\nkind: Cluster\nmetadata:\n  name: sitevisor-db-cluster\n  namespace: postgres-operator\nspec:\n  instances: 1\n  imageName: ghcr.io/cloudnative-pg/postgresql:16.2\n  storage:\n    size: 1Gi\n  bootstrap:\n    initdb:\n      database: sitevisordb\n      owner: sitevisoruser\n      secret:\n        name: sitevisor-user-secret\n\" | kubectl apply -f -\n</code></pre>"},{"location":"sitevisor-backend/docs/deployment/postgres-deployment/#inspecting-the-database","title":"Inspecting the database","text":"<p>Create a new Pod which will act as a debug access point:</p> <pre><code>echo \"\napiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres-debug-pod\n  namespace: postgres-operator\nspec:\n  containers:\n  - name: debug-container\n    image: postgres:16.2\n    command: ['sleep', 'infinity']\n  restartPolicy: Always\n\" | kubectl apply -f -\n</code></pre> <p>Check if the Pod is ready:</p> <pre><code>kubectl get pod/postgres-debug-pod -n postgres-operator\n</code></pre> <p>Access the container:</p> <pre><code>kubectl exec -it postgres-debug-pod -n postgres-operator -- /bin/bash\n</code></pre> <p>Connect to PostgreSQL database with <code>psql</code>. Use the password set when deploying PostgreSQL cluster.</p> <pre><code>psql -U sitevisoruser -d sitevisordb -h sitevisor-db-cluster-rw.postgres-operator\n</code></pre> <p>Inspect the database:</p> <pre><code>\\dt\n</code></pre> <p>This should give you a list of tables:</p> <pre><code>                         List of relations\n Schema |               Name               | Type  |     Owner\n--------+----------------------------------+-------+---------------\n public | auth_group                       | table | sitevisoruser\n public | auth_group_permissions           | table | sitevisoruser\n public | auth_permission                  | table | sitevisoruser\n public | auth_user                        | table | sitevisoruser\n public | auth_user_groups                 | table | sitevisoruser\n public | auth_user_user_permissions       | table | sitevisoruser\n public | authtoken_token                  | table | sitevisoruser\n public | django_admin_log                 | table | sitevisoruser\n public | django_content_type              | table | sitevisoruser\n public | django_migrations                | table | sitevisoruser\n public | django_session                   | table | sitevisoruser\n public | sitevisorapi_point               | table | sitevisoruser\n public | sitevisorapi_project             | table | sitevisoruser\n public | sitevisorapi_room                | table | sitevisoruser\n public | sitevisorapi_sensor              | table | sitevisoruser\n public | sitevisorapi_sensortype          | table | sitevisoruser\n public | token_blacklist_blacklistedtoken | table | sitevisoruser\n public | token_blacklist_outstandingtoken | table | sitevisoruser\n</code></pre> <p>Inspect a table with:</p> <pre><code>TABLE sitevisorapi_room;\n</code></pre> <p><code>exit</code> from the pod and delete it when no longer needed:</p> <pre><code>kubectl delete pod/postgres-debug-pod -n postgres-operator\n</code></pre>"}]}